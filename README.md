# QuestAI Platform

QuestAI Platform is a comprehensive solution for generating, refining, and managing educational questions using AI. It features a modern Next.js frontend and a robust FastAPI backend, integrated with Supabase for data & auth and OpenRouter for AI capabilities.

You can reach:

- The deployed application at: https://ai-quest-platform.vercel.app/
- The backend API at: https://ai-quest-platform.onrender.com/docs

## Tech Stack

- **Frontend**: Next.js (React, TypeScript, TailwindCSS, Shadcn UI)
- **Backend**: FastAPI (Python, Pydantic)
- **Database**: Supabase (PostgreSQL)
- **AI**: OpenRouter (OpenAI-compatible API)

## Prerequisites

- **Node.js** (v18 or higher)
- **Python** (v3.9 or higher)
- **Supabase Account** (Project URL & Keys)
- **OpenRouter Account** (API Key)

## Project Structure

- `frontend/`: Next.js application (Next.js)
- `backend/`: FastAPI application (Python FastAPI)

## Setup Instructions

### 1. Backend Setup

1.  Navigate to the backend directory:

    ```bash
    cd backend
    ```

2.  Create and activate a virtual environment:

    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  Install dependencies:

    ```bash
    pip install -r requirements.txt
    ```

4.  Configure environment variables:
    copy `.env.example` to `.env` and fill in your details:

    ```bash
    cp .env.example .env
    ```

    - `SUPABASE_URL`: Your Supabase Project URL
    - `SUPABASE_KEY`: Your Supabase Service Role Key
    - `OPENROUTER_KEY`: Your OpenRouter API Key

5.  Run the server:
    ```bash
    uvicorn app.main:app --reload --port 8000
    ```
    The API will be available at `http://localhost:8000`.

### 2. Frontend Setup

1.  Navigate to the frontend directory:

    ```bash
    cd frontend
    ```

2.  Install dependencies:

    ```bash
    npm install
    ```

3.  Configure environment variables:
    Create a `.env.local` file with the following content:

    ```env
    NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
    ```

    - This URL is used by the Next.js server-side proxy to forward requests to your running backend.

4.  Run the development server:
    ```bash
    npm run dev
    ```
    The application will be available at `http://localhost:3000`.

## Architecture Overview

### Key Components

1.  **Frontend (Next.js)**:
    - Added auth mechanism using cookies.
    - Added proxy to forward requests to the backend.
    - Added pages:
      - Auth pages (login, register)
      - Dashboard pages (dashboard, pdf-workspace, similar-questions, interactive-studio, questions, settings)
    - Added API routes to handle authentication and authorization.
      - /api/auth/login
      - /api/auth/register
      - /api/auth/logout
      - /api/backend/[...path]

2.  **Backend (FastAPI)**:
    - Created /api folder to handle backend requests.
    - Added /core/config to handle environment variables.
    - Added /db folder to handle database connection, migrations and repositories.
    - Added /schemas folder to handle request and response schemas.
    - Added /services folder to handle business logic.
    - Added /utils folder to handle utility functions.
    - Added /ai folder to handle AI requests through agents.
    - Added /orchestration folder to handle orchestration of business logic and agents.

3.  **Database (Supabase)**:
    - Used Supabase for database, auth and storage.
    - Added /db folder to handle database connection, migrations and repositories.
    - Storages:
      - For documents
      - For similar questions images
    - Tables:
      - sessions: Stores user sessions for every AI generation of document based and similarity based questions.
      - documents: Stores documents uploaded by user for document based questions.
      - doc_chunks: Stores document chunks for document based questions with pgvector embeddings.
      - question_seeds: Stores seeds for similarity based questions.
      - questions: Stores questions generated by AI.
      - question_versions: Stores versions of questions generated by AI for refinement of document based questions and similarity based questions.
4.  **Services**:
    - document: Handles document pdf upload, processing, embedding and storage.
    - similar: Handles image upload, processing, analysis and storage.

5.  **AI**:
    - Provides access to LLMs for question generation.
    - Added /ai/prompts folder to handle prompts for AI requests.
    - Added /ai/agents folder to handle agents for AI requests.

6.  **Orchestration**:
    - Handles orchestration of business logic and agents.
    - Added /orchestration folder to handle orchestration of business logic and agents.

7.  **Logger**:
    - Centralized logging configuration (`app/core/logger.py`).
    - Uses `rich` for pretty console output in development.
    - Request Middleware (`app/middleware/logging.py`) tracks method, path, status, and duration for all API calls.


## ðŸš€ Deployment

### Backend (Render)

1.  Go to [Render](https://render.com/) and sign up/log in.
2.  Click "New" -> "Web Service".
3.  Connect your GitHub repository.
4.  Configure the settings:
    - **Build Command**: `pip install -r requirements.txt`
    - **Start Command**: `uvicorn app.main:app --host [IP_ADDRESS] --port $PORT`
    - **Environment**: Python
    - **Region**: Choose your preferred region.
5.  Add the required environment variables (SUPABASE_URL, SUPABASE_KEY, OPENROUTER_KEY).
6.  Click "Create Web Service".

### Frontend (Vercel)

1.  Go to [Vercel](https://vercel.com/) and sign up/log in.
2.  Click "Add New..." -> "Project".
3.  Import your frontend repository.
4.  Configure the settings:
    - **Framework**: Next.js
    - **Build Command**: `npm run build`
    - **Output Directory**: `.next`
    - **Install Command**: `npm install`
    - **Root Directory**: `frontend`
5.  Add the required environment variables:
    - `NEXT_PUBLIC_API_BASE_URL`: Set this to your Render backend URL (e.g., `https://ai-quest-platform.onrender.com`).
6.  Click "Deploy".



## Planning strategy
I started with planning the architecture of the application and came up with the following:
- Auth
- Document based questions
  - Upload document
  - Split document into chunks
  - Embed document chunks
  - Generate questions
  - Refine questions
- Similarity based questions
  - Upload image
  - Generate questions
  - Refine questions

My plan was:

**Backend first**
- Design the structure of the backend.
    - Added integrations of Supabase Auth, Database and Storage.
    - Created database schema for documents, question seeds, questions and sessions.
    - First I just implemented the authentication api routes and tested them with postman.
    - Then I implemented the document based generation end-to-end.
        - upload â†’ extract PDF â†’ chunk â†’ embed â†’ retrieve context â†’ LLM structured generation â†’ save questions
    - Next added refinement for document based questions end-to-end.
    - Then implemented the similarity based generation end-to-end.
        - upload â†’ extract image â†’ analyze â†’ LLM structured generation â†’ save questions

**Frontend second**
- First I just make some design by using Google Stitch.
- Design the structure of the frontend (pages, components, api routes, etc.).
- Implemented the authentication.
- Implemented the document based questions.
- Implemented the similarity based questions.



## AI tools I used:
- Google Gemini 3 Pro for code review and debugging (Antigravity).
- Google Stitch for UI design.
- ChatGPT Codex for database design and prompts.


## Where AI tools failed and how I manually intervened
- JSON schema mismatch:

    Model returned question instead of question_text, so strict schema validation failed and retried.

- Next.js build error on Vercel (useSearchParams requires Suspense):

    useSearchParams requires Suspense, so I wrapped the component with Suspense.

- Render deployment port scan timeout:

    Render detected no open port (app wasnâ€™t binding correctly). I updated start command to bind to:
    0.0.0.0:$PORT (Render-required)